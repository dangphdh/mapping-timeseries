# Architecture Overview - Generic Mapping Engine

## ðŸ“ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  Quick Interface:           Advanced Interface:                      â”‚
â”‚  map_tables_simple()        GenericMappingEngine class              â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Configuration Layer                             â”‚
â”‚                      MappingConfig class                             â”‚
â”‚  â€¢ Method selection (correlation/dtw/auto)                          â”‚
â”‚  â€¢ Performance parameters (partitioning, caching)                   â”‚
â”‚  â€¢ Algorithm parameters (max_lag, window_size, etc.)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Validation Layer                                â”‚
â”‚                      DataValidator class                             â”‚
â”‚  â€¢ Schema validation                                                â”‚
â”‚  â€¢ Data quality checks                                              â”‚
â”‚  â€¢ Null/negative value detection                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Preparation Layer                            â”‚
â”‚  â€¢ Column normalization                                             â”‚
â”‚  â€¢ Spark optimization (repartitioning, caching)                     â”‚
â”‚  â€¢ Table merging                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Mapping Engine Core                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Correlation   â”‚    â”‚     DTW       â”‚    â”‚     Auto      â”‚      â”‚
â”‚  â”‚   Method      â”‚    â”‚   Method      â”‚    â”‚   Selection   â”‚      â”‚
â”‚  â”‚               â”‚    â”‚               â”‚    â”‚               â”‚      â”‚
â”‚  â”‚ â€¢ Fast        â”‚    â”‚ â€¢ Accurate    â”‚    â”‚ â€¢ Adaptive    â”‚      â”‚
â”‚  â”‚ â€¢ Linear      â”‚    â”‚ â€¢ Non-linear  â”‚    â”‚ â€¢ Best of     â”‚      â”‚
â”‚  â”‚ â€¢ Lag-based   â”‚    â”‚ â€¢ Path-based  â”‚    â”‚   both        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚          â”‚                    â”‚                    â”‚                â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                               â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Spark Optimization Layer                          â”‚
â”‚  â€¢ Pandas UDF for distributed processing                           â”‚
â”‚  â€¢ Broadcast joins for small tables                                â”‚
â”‚  â€¢ Partition-level parallelism                                     â”‚
â”‚  â€¢ Adaptive query execution                                         â”‚
â”‚  â€¢ Arrow-based data transfer                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Output Layer                                 â”‚
â”‚  â€¢ Standardized schema                                              â”‚
â”‚  â€¢ Metadata enrichment (method, correlation, cost)                 â”‚
â”‚  â€¢ Processing statistics                                            â”‚
â”‚  â€¢ Delta/Parquet export ready                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”„ Processing Flow

### 1. Input Phase
```
User Tables (table1, table2)
     â”‚
     â”œâ”€> Schema Validation
     â”œâ”€> Data Quality Checks
     â””â”€> Column Mapping
```

### 2. Preparation Phase
```
Validated Tables
     â”‚
     â”œâ”€> Normalize column names
     â”œâ”€> Repartition for parallel processing
     â”œâ”€> Cache if configured
     â””â”€> Merge on key + time columns
```

### 3. Analysis Phase
```
Merged Data
     â”‚
     â”œâ”€> Group by entity (key_col)
     â”‚
     â”œâ”€> For each entity:
     â”‚   â”‚
     â”‚   â”œâ”€> Correlation Method:
     â”‚   â”‚   â”œâ”€> Compute correlation for each lag
     â”‚   â”‚   â”œâ”€> Select optimal lag
     â”‚   â”‚   â””â”€> Apply lag and join tables
     â”‚   â”‚
     â”‚   â”œâ”€> DTW Method:
     â”‚   â”‚   â”œâ”€> Build cost matrix
     â”‚   â”‚   â”œâ”€> Find optimal path
     â”‚   â”‚   â””â”€> Extract alignments
     â”‚   â”‚
     â”‚   â””â”€> Auto Method:
     â”‚       â”œâ”€> Compute correlation
     â”‚       â”œâ”€> If high correlation: use correlation
     â”‚       â””â”€> If low correlation: use DTW
     â”‚
     â””â”€> Combine results
```

### 4. Output Phase
```
Mapping Results
     â”‚
     â”œâ”€> Add metadata (method, timestamps)
     â”œâ”€> Collect statistics
     â””â”€> Return DataFrame
```

## ðŸ§© Component Details

### Core Components

| Component | File | Purpose | Key Features |
|-----------|------|---------|--------------|
| **MappingConfig** | mapping_engine.py | Configuration management | Parameter validation, defaults |
| **DataValidator** | mapping_engine.py | Input validation | Schema checks, quality metrics |
| **GenericMappingEngine** | mapping_engine.py | Main engine | Orchestration, method selection |
| **Correlation UDF** | mapping_engine.py | Correlation analysis | Pandas UDF, lag optimization |
| **DTW UDF** | mapping_engine.py | DTW analysis | Pandas UDF, path finding |

### Helper Functions

| Function | Purpose | Optimization |
|----------|---------|--------------|
| `normalize_series()` | Z-score normalization | Vectorized numpy |
| `compute_correlation_with_lags()` | Find optimal lag | Scipy correlation |
| `dtw_distance()` | Compute DTW path | Window constraint |
| `map_tables_simple()` | Simplified interface | Default config |

## ðŸš€ Performance Features

### Spark Optimizations

1. **Partitioning**
   - Automatic repartitioning by key column
   - Configurable partition count
   - Coalesce partitions after processing

2. **Caching**
   - Optional intermediate result caching
   - Automatic cache cleanup
   - Memory-aware caching

3. **Broadcast Joins**
   - Small table broadcasting
   - Configurable threshold
   - Dimension table optimization

4. **Parallel Processing**
   - Pandas UDF for distributed computation
   - Per-entity parallelism
   - Arrow-based data transfer

5. **Adaptive Execution**
   - Dynamic partition coalescing
   - Runtime query optimization
   - Skew handling

## ðŸ“Š Scalability

### Performance Characteristics

| Dataset Size | Method | Expected Throughput | Memory Usage |
|--------------|--------|-------------------|--------------|
| Small (< 1M rows) | Correlation | 5,000-10,000 rec/s | Low |
| Medium (1M-10M) | Correlation | 2,000-5,000 rec/s | Medium |
| Large (> 10M) | Correlation | 1,000-3,000 rec/s | Medium |
| Small (< 1M rows) | DTW | 500-1,000 rec/s | Medium |
| Medium (1M-10M) | DTW | 200-500 rec/s | High |
| Large (> 10M) | DTW | 100-300 rec/s | High |

### Scaling Recommendations

- **< 1M rows**: Default settings (200 partitions)
- **1M-10M rows**: 400 partitions, enable caching
- **10M-100M rows**: 800+ partitions, selective caching
- **> 100M rows**: Process in batches, use correlation method

## ðŸ” Data Quality

### Validation Checks

1. **Schema Validation**
   - Required column presence
   - Data type compatibility
   - Column name mapping

2. **Quality Metrics**
   - Null value percentage
   - Negative value detection
   - Row count validation

3. **Warnings**
   - High null rate (> 10%)
   - High negative rate (> 5%)
   - Low match rate

## ðŸ“¦ File Structure

```
mapping-timeseries/
â”œâ”€â”€ mapping_engine.py          (31KB) - Main engine implementation
â”œâ”€â”€ test_mapping_engine.py     (8.6KB) - Comprehensive tests
â”œâ”€â”€ example_usage.py           (5.2KB) - Quick start example
â”œâ”€â”€ README.md                  (9.9KB) - Documentation
â”œâ”€â”€ .gitignore                 - Exclude build artifacts
â”œâ”€â”€ 01_setup.oy               - Original setup (reference)
â”œâ”€â”€ 02_corr_mapping.p         - Original correlation notebook
â”œâ”€â”€ 03_dtw_mapping.py         - Original DTW notebook
â”œâ”€â”€ 04_comparision.py         - Original comparison notebook
â””â”€â”€ 05_prod_dev.py            - Original production notebook
```

## ðŸŽ¯ Use Case Examples

### 1. Customer Transaction â†’ Revenue
```python
# Map customer transactions to revenue with 1-3 month lag
result = map_tables_simple(
    spark, transactions, revenue,
    key_col='customer_id', time_col='month',
    value1_col='txn_amount', value2_col='revenue',
    method='correlation', max_lag=3
)
```

### 2. Product Sales â†’ Profit (Complex Pattern)
```python
# Use DTW for non-linear sales-to-profit relationship
config = MappingConfig(method='dtw', window_size=7)
engine = GenericMappingEngine(spark, config)
result = engine.map_tables(
    sales, profit,
    key_col='product_id', time_col='week',
    value1_col='units_sold', value2_col='profit'
)
```

### 3. Marketing Spend â†’ Conversions (Mixed)
```python
# Auto-select method based on pattern complexity
result = map_tables_simple(
    spark, marketing_spend, conversions,
    key_col='campaign_id', time_col='date',
    value1_col='spend', value2_col='conversions',
    method='auto'
)
```

## ðŸ”§ Customization Points

### Extending the Engine

1. **Add New Mapping Methods**
   - Implement method in `GenericMappingEngine`
   - Create corresponding UDF factory
   - Update config options

2. **Custom Validation Rules**
   - Extend `DataValidator` class
   - Add validation methods
   - Update validation pipeline

3. **Performance Tuning**
   - Adjust `MappingConfig` parameters
   - Modify partitioning strategy
   - Configure caching policy

---

**Created by:** dangphdh  
**Last Updated:** 2025-01-06  
**Version:** 1.0.0
